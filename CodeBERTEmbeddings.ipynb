{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e086f350",
   "metadata": {},
   "source": [
    "## Not working code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c1cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50a1fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init CodeBERT\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model_bert = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51fee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT forget 'keep_default_na=False' --> otherwise some NaN values in read data\n",
    "df = pd.read_csv('./big-vul_dataset/line_sample_20p_balanced_ratio.csv', skipinitialspace=True, low_memory=True, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into training and validation sets\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(df['line'], df['vul'], test_size=0.2, random_state=42)\n",
    "\n",
    "print('X_tr shape:',X_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25f51e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(list_of_strings):\n",
    "    embeddings = []\n",
    "    for s in list_of_strings:\n",
    "        # tokenize\n",
    "        code_tokens=tokenizer_bert.tokenize(s)\n",
    "        # add special tokens\n",
    "        tokens=[tokenizer_bert.cls_token]+code_tokens+[tokenizer_bert.sep_token]\n",
    "        # convert to IDs\n",
    "        tokens_ids=tokenizer_bert.convert_tokens_to_ids(tokens)\n",
    "        print(tokens_ids)\n",
    "        # create embedding\n",
    "        context_embeddings=model_bert(torch.tensor(tokens_ids)[None,:])[0]\n",
    "        # reforming tensor into numpy array (check needed!)\n",
    "        embeddings.append(context_embeddings)\n",
    " \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4db347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2544, 3023, 5457, 195, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = bert_encode([\"int x = 5\"])\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "293138d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2544, 2544, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.1278,  0.3240,  0.0276,  ..., -0.1703, -0.2517,  0.3435],\n",
       "          [-0.5561,  0.4523, -0.0856,  ..., -0.1599, -0.4564,  0.1024],\n",
       "          [-0.6194,  0.5343, -0.1553,  ..., -0.4806, -0.2627,  0.1478],\n",
       "          [-0.1275,  0.3236,  0.0281,  ..., -0.1705, -0.2517,  0.3432]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = bert_encode([\"intint\"])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5115bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how big a batch of entries should be (depending on RAM)\n",
    "batch_size = 100\n",
    "\n",
    "# number of epochs is calulated based on the batch_size\n",
    "epochs = math.ceil(len(X_tr)/batch_size)\n",
    "\n",
    "# split the dataframes (X_tr, y_tr) into an array of dataframes (number of epochs)\n",
    "batchesX = np.array_split(X_tr, epochs)\n",
    "batchesY = np.array_split(y_tr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883de3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d469a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and initialisation of generic MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(random_state=1)\n",
    "\n",
    "# iterate over the number of epochs (manually decreased the number of epochs here to ensure fast processing)\n",
    "for i in range(epochs-50):\n",
    "    print(i)\n",
    "    # take a batch and process it and partial_fit the model to the batch\n",
    "    X_batch, Y_batch = batchesX[i], batchesY[i]\n",
    "    encodedBatch = bert_encode(X_batch.tolist())\n",
    "    clf.partial_fit(encodedBatch, Y_batch, classes=np.unique(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "y_pred = clf.predict(bert_encode(X_val[:batch_size*3]))\n",
    "print(classification_report(y_val[:batch_size*3], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31470160",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_bert = bert_encode(X_tr.tolist())\n",
    "X_val_bert = bert_encode(X_val.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f57434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LR model\n",
    "vul_model = LogisticRegression()\n",
    "# train\n",
    "vul_model = vul_model.fit(X_tr_bert, y_tr)\n",
    "# predict\n",
    "pred_vul = vul_model.predict(X_val_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_val, pred_bert))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
